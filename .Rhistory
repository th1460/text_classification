classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ])) * input[example, ]
a <- - weights[1] / weights[2]
b <- - weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
weights <- c(0.25, 0.2, 0.35) # pesos iniciais (aleatórios)
eta <- .5 # taxa de aprendizado
input <- dataset %>% as.matrix() %>% .[, 1:2] # input
input %<>% cbind(bias = 1) # inclusão do viés (intercepto)
# inspired by Kubat: An Introduction to Machine Learning, p. 72
plot_line <- function(w, col = "blue", add = TRUE)
curve(-w[1] / w[2] * x - w[3] / w[2], xlim = c(-0.5, 1.5), ylim = c(-0.5, 1.5), col = col, lwd = 3, xlab = "Input 1", ylab = "Input 2", add = add)
neuron <- function(input) as.vector(ifelse(input %*% weights > 0, 1, 0)) # step function on scalar product of weights and input
eta <- 0.5 # learning rate
# examples
input <- matrix(c(1, 0,
0, 0,
1, 1,
0, 1), ncol = 2, byrow = TRUE)
input <- cbind(input, 1) # bias for intercept of line
output <- c(0, 1, 0, 1)
weights <- c(0.25, 0.2, 0.35) # random initial weights
plot_line(weights, add = FALSE); grid()
points(input[ , 1:2], pch = 16, col = (output + 2))
# training of weights of neuron
for (example in 1:length(output)) {
weights <- weights + eta * (output[example] - neuron(input[example, ])) * input[example, ]
plot_line(weights)
}
plot_line(weights, col = "black")
dataset %>% DT::datatable(rownames = FALSE,
options = list(dom = "t"),
colnames = c("Input 1", "Input 2", "Output"))
dataset %>% DT::datatable(rownames = FALSE,
options = list(dom = "t"),
colnames = c("Input 1", "Input 2", "Output"))
weights <- c(0.25, 0.2, 0.35) # pesos iniciais (aleatórios)
eta <- .3 # taxa de aprendizado
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ])) * input[example, ]
a <- - weights[1] / weights[2]
b <- - weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
weights <- c(0.25, 0.2, 0.35) # pesos iniciais (aleatórios)
eta <- .7 # taxa de aprendizado
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ])) * input[example, ]
a <- - weights[1] / weights[2]
b <- - weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
output
input <- matrix(c(1, 0,
0, 0,
1, 1,
0, 1), ncol = 2, byrow = TRUE)
input
input <- cbind(input, 1)
input
weights <- c(0.25, 0.2, 0.35) # pesos iniciais (aleatórios)
eta <- .5 # taxa de aprendizado
classifier <- function(a, b){
y <- function(x, a, b) a * x + b
stat_function(fun = y,
args = list(a, b),
colour = "#3333ff",
alpha = .8,
size = 1.5)
}
classifier <- function(a, b){
stat_function(fun = function(x, a, b) a * x + b,
args = list(a, b),
colour = "#3333ff",
alpha = .8,
size = 1.5)
}
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ])) * input[example, ]
a <- - weights[1] / weights[2]
b <- - weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
(g1 <- dataset %>%
ggplot() +
aes(input1, input2, colour = as.factor(output)) +
geom_point(size = 5) +
scale_x_continuous(limits = c(-1.5, .5)) +
labs(x = "Input 1", y = "Input 2", colour = "Output") +
theme_minimal())
(g1 <- dataset %>%
ggplot() +
aes(input1, input2, colour = as.factor(output)) +
geom_point(size = 5) +
scale_x_continuous(limits = c(-.5, 1.5)) +
labs(x = "Input 1", y = "Input 2", colour = "Output") +
theme_minimal())
(g1 <- dataset %>%
ggplot() +
aes(input1, input2, colour = as.factor(output)) +
geom_point(size = 5) +
scale_x_continuous(limits = c(-.5, 1.5)) +
scale_y_continuous(limits = c(-.5, 1.5)) +
labs(x = "Input 1", y = "Input 2", colour = "Output") +
theme_minimal())
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ])) * input[example, ]
a <- - weights[1] / weights[2]
b <- - weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ])) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
neuron <- function(input, weights) as.vector(ifelse(input %*% weights > 0, 1, 0))
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
g1 + 1 %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:2 %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
g1 + 1 %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:3 %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
}
gradientDescent(output, input, weights, eta)
gradientDescent(output, input, weights, eta)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
weights
gradientDescent(output = output, input = input, weights = weights, eta = eta)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
classifier <- function(a, b){
y <- function(x, a, b) a * x + b # função linear
stat_function(fun = y,
args = list(a, b),
colour = "#3333ff",
alpha = .8,
size = 1.5)
}
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
gradientDescent <- function(output, input, weights, eta){
g1 +
for(example in 1:length(output)){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
}
gradientDescent(output, input, weights, eta)
g1 +
for(example in 1:length(output)){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
weights
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
tibble(a, b)
}
1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
neuron <- function(input) as.vector(ifelse(input %*% weights > 0, 1, 0))
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
tibble(a, b)
}
1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
neuron <- function(input, weights) as.vector(ifelse(input %*% weights > 0, 1, 0))
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
tibble(a, b)
}
1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
example = 1
weights <- c(0.25, 0.2, 0.35)
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
tibble(a, b)
}
1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
weights
.25/.2
.35/.2
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
tibble(a, b)
}
1:length(output) %>% purrr::map_dfr(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
classifier <- function(data, a, b){
y <- function(x, a, b) a * x + b # função linear
stat_function(data, fun = y,
args = list(a, b),
colour = "#3333ff",
alpha = .8,
size = 1.5)
}
g1 + classifier(data = gradientDescent(output, input, weights, eta))
classifier <- function(a, b){
y <- function(x, a, b) a * x + b # função linear
stat_function(data, fun = y,
args = list(a, b),
colour = "#3333ff",
alpha = .8,
size = 1.5)
}
dados <- gradientDescent(output, input, weights, eta)
steps <- gradientDescent(output, input, weights, eta)
classifier <- function(a, b){
y <- function(x, a, b) a * x + b # função linear
stat_function(fun = y,
args = list(a, b),
colour = "#3333ff",
alpha = .8,
size = 1.5)
}
g1 + classifier(steps$a, steps$b)
steps$a
g1 + classifier(steps$a[1], steps$b[1])
g1 +
classifier(steps$a[1], steps$b[1]) +
classifier(steps$a[2], steps$b[2]) +
classifier(steps$a[3], steps$b[3]) +
classifier(steps$a[4], steps$b[4])
a = NULL
b = NULL
for(example in 1:length(output)){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- c(a, -weights[1] / weights[2])
b <- c(b, -weights[3] / weights[2])
}
a
b
tibble(a, b)
classifier <- function(a, b){
stat_function(fun = function(x, a, b) b * x + a,
args = list(a, b),
colour = "#3333ff",
alpha = .8,
size = 1.5)
}
gradientDescent <- function(output, input, weights, eta){
updateWeights <- function(example, output, input, weights, eta){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- -weights[1] / weights[2]
b <- -weights[3] / weights[2]
classifier(a, b)
}
g1 + 1:length(output) %>% purrr::map(~ updateWeights(.x, output, input, weights, eta))
}
gradientDescent(output, input, weights, eta)
?map2
classifier <- function(a, b){
y <- function(x, a, b) a * x + b # função linear
stat_function(fun = y,
args = list(a, b),
colour = "#3333ff",
alpha = .8,
size = 1.5)
}
tibble(a, b)
g1 + map2(tibble(a, b), ~ classifier(.x, .y))
g1 + purrr::map2(tibble(a, b), ~ classifier(.x, .y))
g1 + purrr::map2(tibble(a, b), ~ classifier)
g1 + purrr::map2(tibble(a, b), classifier(a, b))
g1 + purrr::map2(tibble(a, b), .f = classifier(a, b))
g1 + purrr::pmap(tibble(a, b), classifier)
gradientDescent <- function(output, input, weights, eta){
a = NULL
b = NULL
for(example in 1:length(output)){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- c(a, -weights[1] / weights[2])
b <- c(b, -weights[3] / weights[2])
}
tibble(a, b)
}
g1 + purrr::pmap(gradientDescent(output, input, weights, eta), classifier)
steps <-
gradientDescent(output, input, weights, eta)
steps <-
gradientDescent(output, input, weights, eta)
steps %>%
DT::datatable()
weights
weights <- c(0.25, 0.2, 0.35) # pesos iniciais (aleatórios)
gradientDescent <- function(output, input, weights, eta){
a = NULL
b = NULL
for(example in 1:length(output)){
weights <- weights + eta * (output[example] - neuron(input[example, ], weights)) * input[example, ]
a <- c(a, -weights[1] / weights[2])
b <- c(b, -weights[3] / weights[2])
}
tibble(a, b)
}
steps <-
gradientDescent(output, input, weights, eta)
steps %>%
DT::datatable()
steps <-
gradientDescent(output, input, weights, eta)
steps %>%
DT::datatable(options = list(dom = "t"))
g1 + purrr::pmap(steps, classifier)
g1 +
purrr::pmap(steps[-3, ], classifier)
g1 +
purrr::pmap(steps[-4, ], classifier)
g1 +
purrr::pmap(steps[-length(output), ], classifier)
steps
classifier <- function(a, b, color){
stat_function(fun = function(x, a, b) a * x + b,
args = list(a, b),
colour = color,
alpha = .8,
size = 1.5)
}
classifier <- function(a, b){
stat_function(fun = function(x, a, b) a * x + b,
args = list(a, b),
colour = "#3333ff",
alpha = .8,
size = 1.5)
}
classifier <- function(a, b, color = "#3333ff"){
stat_function(fun = function(x, a, b) a * x + b,
args = list(a, b),
colour = color,
alpha = .8,
size = 1.5)
}
g1 +
purrr::pmap(steps[-length(output), ], classifier)
steps[length(output), ]
steps[length(output), 'a']
g1 +
purrr::pmap(steps[-length(output), ], classifier) +
classifier(a = steps[length(output), 'a'],
b = steps[length(output), 'b'],
color = "red")
g1 +
purrr::pmap(steps[-length(output), ], classifier) +
classifier(a = steps[length(output), 'a'] %>% as.vector(),
b = steps[length(output), 'b'] %>% as.vector(),
color = "red")
steps[length(output), 'a'] %>% as.vector()
steps[length(output), 'b'] %>% as.vector()
g1 +
purrr::pmap(steps[-length(output), ], classifier) +
classifier(a = 3.75, b = -1.75)
g1 +
purrr::pmap(steps[-length(output), ], classifier) +
classifier(a = 3.75, b = -1.75, color = "red")
g1 +
purrr::pmap(steps[-length(output), ], classifier) +
classifier(a = 3.75, b = -1.75, color = "#006600")
g1 +
purrr::pmap(steps[-length(output), ], classifier(color = "#006600")) +
classifier(a = 3.75, b = -1.75, color = "#006600")
g1 +
purrr::pmap(steps, classifier) +
classifier(a = 3.75, b = -1.75, color = "#006600")
g1 +
purrr::pmap(steps, classifier) +
classifier(a = 3.75, b = -1.75, color = "#cc3300")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
g1 + purrr::pmap(steps, classifier) + classifier(a = 3.75, b = -1.75, color = "#cc3300")
g1 <- dataset %>%
ggplot() +
aes(input1, input2, colour = as.factor(output)) +
geom_point(size = 5) +
scale_x_continuous(limits = c(-.5, 1.5)) +
scale_y_continuous(limits = c(-.5, 1.5)) +
labs(x = "Input 1", y = "Input 2", colour = "Output") +
theme_minimal()
